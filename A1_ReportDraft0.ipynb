{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "“A1_ReportDraft0.ipynb”的副本",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pienight/Machinelearning/blob/master/A1_ReportDraft0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ta-kZVJ-SDf",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"Generative Adversarial Nets\"\n",
        "https://github.com/pienight/Machinelearning/blob/master/A1_ReportDraft0.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEWX6sW2-SDi",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWvrJ0fB4WfO",
        "colab_type": "text"
      },
      "source": [
        "This report would review the paper GOO14 and present findings from it. The paper GOO14_GAN named \"Generative Adversarial Nets\" was published by Goodfellow et al. in 2014. Its subject is about deep learning which is extremely popular recently. At the meantime, after the publication of this article, we have witnessed GAN-related researches springing up. This paper can be regarded as the pioneering work in the field of GAN, which is also the reason we chose it to review."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p_D4ZQj-SDk",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VszCck-rnGKG",
        "colab_type": "text"
      },
      "source": [
        "The paper is about the design of a new method in machine learning which is Generative Adversarial Nets (GAN). It aims to provide a new method that could solve the current generative problems in deep learning and upgrade it in a new way. At the beginning, the article generally introduces current backgrounds in machine learning and discusses different works related, such as deep belief networks (DBNs) and generative stochastic network (GSN). The author then introduces the thought that two machine learning algorithms concerted together as adversarial nets and enhance themselves while beating each other. This article firstly shapes the model by graphics and general description to help understanding. Then a mathematical proof of the feasibility and convergence of the new method is given. After this, a demonstration example is provided, and the outputs are shown as satisfactory results. Finally, visible advantages and disadvantage of this method are discussed. Then the article is concluded, and the future work direction is summarized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClbMqFy3-SDp",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j7cBJlgyHq5",
        "colab_type": "text"
      },
      "source": [
        "The innovation is significant since this GAN article offers a new approach to learning and generating by combining algorithms which means a computer would study and output on its own. It further realizes the autonomy and independence of AI. And in the article the approach is strictly proved in theory which allows people focus on the algorithm acquiescing in the rationality of algorithms. As a background at the time of the research in 2014, deep learning was very popular, and many tools had already been developed. People have a task for unsupervised study that is generative model. There were many different designs to implement a high performance generative, like Variational auto-encoder (VAE)(Kingma & Welling 2013) and the generative stochastic network (GSN) framework(Bengio et al. 2014). These researches pave the way and make it possible to deal with generative model. GAN’s preeminence are mainly two aspects: better output and less progress(Goodfellow 2016). After GAN is published, many researchers come in and form a new research field gradually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1RCV-bO-SDt",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mStWjkD-SDv",
        "colab_type": "text"
      },
      "source": [
        "Technical quality of this paper is very high. As an article that provides a new method, it not only gives out details about the design and the main ideas, but also demonstrates itself in practice and theory, which are full of technique. Although it's only nine pages short, but it's a complete article with no obvious mistakes. Every part of the technology could be accessed and tested by readers. And the design source code is open, which makes it easy to duplicate to other dataset and start a new experiment. The only shortcoming of this paper might be it require readers have fundamental knowledge of machine learning and some basic mathematics knowledge while reading. It has been five years that numerous articles are inspired by this paper which is also a proof of its quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOFyCC_S-SDy",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLUt0xFb-SD0",
        "colab_type": "text"
      },
      "source": [
        "The domain is large, so the technology is proper. This technology has been developed in a fast speed and been used in many different areas. It is also its most interesting part. It is widely used currently. GAN and other similar algorithms mean the ability to study. People are using it to create new output in the areas that they have no idea like painting. If AI would be smart enough, it can imitate many things via this kind of learning. A long-term research direction of GAN is overcome its own drawbacks like model collapse. Researches are done to solve problems and to optimize GAN in various ways, such as f-GAN, WGAN. Due to the special area, deep learning methods can be used into many areas other than IT. The precious thing of GAN is not only the codes and algorithm, but also the design that two adversarial parts. Other industrial can learn this to develop their own strategy. For example, student may not only study to generate the correct answers, but also need to set a self-detector that figure out what answers are wrong. Unless the GAN, students would approach perfect balance and there would be little differences between their understanding and correct ones. All the things that the teacher needs to do is to encourage the student to give out answers and avoid model collapse. Personally, I believe there is still chance to make an improvement in current GAN field by applying transform learning idea. I search a little bit but did not find one. Also, I am curious in how to directly or indirectly edit the rules in neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rpq2lwTT-SD1",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBQV_CZV-SD2",
        "colab_type": "text"
      },
      "source": [
        "I believe this is a good sample on presentation. One issue of it is the background and related works seems have not too much relationship with the technology of the paper. Another problem is mentioned above that readers needs some background in this area and some fundamental math knowledge. In addition to these two points, the narrative in this paper is very appropriate, only in a few words there are some misunderstandings. But in the rigorous proof and definition part, the article is clearer. In addition to these two points, the narrative in this paper is very appropriate. There are only a few words that are misunderstandings. But in the rigorous proof and definition part, the article is much clearer. In addition, there are example, graphics and qualitative illustrations, followed by a mathematical discussion, which is equivalent to providing two methods to help people with different levels of knowledge to understand. Even if readers don't understand the mathematical proof, they need only understand the first half of qualitative analysis, and then combine the results of mathematical proof, readers can get the main idea of this article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs9i90si-SD4",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A. & Bengio, Y. 2014, 'Generative adversarial nets', Advances in neural information processing systems, pp. 2672-80.\n",
        "\n",
        "Bengio, Y., Laufer, E., Alain, G. & Yosinski, J. 2014, 'Deep generative stochastic networks trainable by backprop', International Conference on Machine Learning, pp. 226-34.\n",
        "\n",
        "Goodfellow, I. 2016, 'NIPS 2016 tutorial: Generative adversarial networks', arXiv preprint arXiv:1701.00160.\n",
        "\n",
        "Kingma, D.P. & Welling, M. 2013, 'Auto-encoding variational bayes', arXiv preprint arXiv:1312.6114.\n",
        "\n"
      ]
    }
  ]
}