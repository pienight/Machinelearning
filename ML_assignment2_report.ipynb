{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pienight/Machinelearning/blob/master/ML_assignment2_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5se1qBYqycO",
        "colab_type": "text"
      },
      "source": [
        "# **Flowers Classification based on CNN Models**\n",
        "\n",
        "Hongwei Sheng 12871974\n",
        "\n",
        "Ying Zhao 12830802\n",
        "\n",
        "Chenyang Zhang 12713513"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gTwc3-_qJcP",
        "colab_type": "text"
      },
      "source": [
        "# **Links:**\n",
        "AlexNet: https://github.com/pienight/Machinelearning/blob/master/MLass2_Alexnet.ipynb\n",
        "\n",
        "GoogleNet: https://github.com/pienight/Machinelearning/blob/master/MLass2_googlenetmodel.ipynb\n",
        "\n",
        "VGG16: https://github.com/pienight/Machinelearning/blob/master/MLass2_VGG16.ipynb\n",
        "\n",
        "Dataset: https://www.kaggle.com/saidakbarp/17-category-flowers/\n",
        "\n",
        "Paper:  https://github.com/pienight/Machinelearning/blob/master/ML_assignment2_report.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFeFTJA41KCb",
        "colab_type": "text"
      },
      "source": [
        "# **1.Introduction**\n",
        "Flowers have important ornamental and economic value. However, there are many kinds of flowers and many kinds of flower petals. At present, the identification and management of flower patterns are mainly carried out manually, which is not efficient and is prone to errors for ordinary non-professionals. On the other hand, image recognition applications and related theoretical research are developing rapidly, and intelligent recognition of images has become one of the most important development and application goals in the field of artificial intelligence.\n",
        " \n",
        "Classification is the most famous problem in identifying image categories in computer vision, and it is also the basis for other tasks such as target detection, behavior tracking, and image segmentation. The application of image classification covers transportation, security, medical, government, Internet and other fields. Its application scenarios include traffic scene recognition, face detection, intelligent video analysis, and medical image recognition.\n",
        " \n",
        "In recent years, the Convolutional Neural Network (CNN) has achieved amazing results in the field of image recognition. CNN takes the image pixel information as input, extracts and abstracts the feature through convolution, and directly outputs the image recognition result. This method retains the original image information to a great extent, and the end-to-end learning method has achieved good results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeZhCLgP1JY8",
        "colab_type": "text"
      },
      "source": [
        "# **2.Dataset**\n",
        "The dataset we use is the 17flowers dataset. In flower dataset, there are 17 classes with 680 images in train dataset, 340 images in test dataset and 340 images in validation dataset. It must be mentioned that there are only 660 pictures in train2 data, and the other eight data sets all fit what I said above. \n",
        "\n",
        "![dataset](https://raw.githubusercontent.com/pienight/Machinelearning/master/datasetimage.png)\n",
        "\n",
        "Among them, the training set is used to train the model; the validation set is used to make the model selection; the test set is used to evaluate the selected model.\n",
        "\n",
        "Before the model is trained, we must choose the model to be trained. After selecting the model, we will start training. The goal of training is to determine the parameters of the model. Training is usually done by designing the loss function and then optimizing the loss function. In most cases, we don't know which model is suitable, so we often need to train a variety of models. After training, we will get the results of multiple models. We hope to choose the most suitable ones from these trained models. model. We test all models by using the validation set and then select the one with the lowest error rate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67V4teOs1Jh9",
        "colab_type": "text"
      },
      "source": [
        "# **3.Methodology**\n",
        "Convolutional neural network (CNN) is a special deep neural network model. In this paper, we used three CNN models to train and test separately, namely VGG16, GoogleNet, and Alexnet.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bp0Sd841Jlx",
        "colab_type": "text"
      },
      "source": [
        "## **3.1 AlexNet**\n",
        "The baseline architecture that we used is AlexNet model which is a classic model for CNN. The following figure 6 is the network structure of Alex-Net, including five convolutional layers and three full connection layers. It can be seen that the framework is divided into upper and lower branches, which aims to facilitate parallel training using GPU at the same time. At the third layer of convolution and full connection, the upper and lower branches can interact with each other. \n",
        "\n",
        "![Alexnet figure1](https://raw.githubusercontent.com/pienight/Machinelearning/master/Alexnet_architecture1.png)\n",
        "\n",
        "In the customized architecture, we use 4 convolutional layer, 5 pooling layer, 2 dropout layer, 1 flatten layer, 2 dense layer.\n",
        "\n",
        "![Alexnet figure2](https://raw.githubusercontent.com/pienight/Machinelearning/master/Alexnet_architecture2.png)\n",
        "\n",
        "The convolutional layer is the basic operation layer in the convolutional neural network. Convolution is a local operation in which a certain size of convolution kernel is applied to a local image region to obtain the local information of the image. The parameters of the convolution kernel in the convolution network are learned through network training. we are going to use a little convolution kernel of 3 * 3. \n",
        "The pooling layer contains no parameters to learn. When pooling is set, only the average or Max, kernel size and stride parameters of the pooling operation should be specified. The introduction of pooling layer is to reduce and abstract the visual input object according to the human visual system. The kernel size of the pooling layer is generally set as 2 * 2. \n",
        "Activation function layer is also called nonlinear mapping layer. In other words, the activation function is introduced to increase the expressiveness of the entire network. Otherwise, the stack of several linear operation layers can only play the role of linear mapping, and complex functions cannot be formed. Intuitively, the activation function simulates the properties of biological neurons, which receive a set of input signals and produce output. I both use Relu and Sigmoid activation function in my model. After the Sigmoid function, the range of output response is compressed to between [0, 1], but for the area on both sides of the function, this part of output will be compressed to 1 or 0. Such treatment may bring about gradient saturation effect. Gradient saturation can be avoided by using the relu function, and the relu function is easier to compute.\n",
        "The Flatten layer is used to one-dimensional the multidimensional input for the transition from the convolution layer to the Dense. Dropout is to randomly drop some weight of the current layer, reduce the complexity of the model, enhance the generalization ability of the model and prevent overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcFMf-hW1JpG",
        "colab_type": "text"
      },
      "source": [
        "## **3.2 VGG16**\n",
        "VGG is an exploration of deep network nerves. VGGNet repeatedly stacks 3x3 small convolution kernels and 2x2 maximum VGG was proposed by the Visual Geometry Group of Oxford, hence the name VGG. \n",
        "The model participated in the 2014 ImageNet Image Classification and Positioning Challenge and achieved excellent results: ranked second in the classification task and ranked first in the positioning task. This network is related to ILSVRC 2014. The main job is to prove that increasing network depth can affect the final performance of the network to some extent.\n",
        "\n",
        "![VGG16 figure1](https://raw.githubusercontent.com/pienight/Machinelearning/master/VGG16-architecture.png)\n",
        "\n",
        "VGG is an exploration of deep network nerves. VGGNet repeatedly stacks 3x3 small convolution kernels and 2x2 maximum pooling layers, and successfully constructs 16~19 layers of deep convolutional neural networks.\n",
        "In the test, the network is first converted into a full convolution network. The first fully connected layer is converted into a 7×7 convolution layer, and the latter two fully connected layers are converted into a 1×1 convolution layer. The result is an N×N×M result, which is called a class score map, where M is equal to the number of categories, and the size of N depends on the input image size Q. When calculating the final score of each category, N×N The values above are averaged, and the result of 1 × 1 × M is obtained. This result is the final category score. This method is called intensive evaluation. This replacement of the fully connected layer is equivalent to applying the fully connected layer to the entire uncut image, and getting a score graph of a category whose number of channels is equal to the number of categories.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_Ykkt9M1Jsk",
        "colab_type": "text"
      },
      "source": [
        "## **3.3 GoogleNet**\n",
        "GoogleNet, first appeared in 2014, has deeper layers and much more accuracy and less computing than previous method like AlexNet. The main theory of it is using 1x1 convolution to reduce and increase the dimension. The baseline used here is inceptionV3. After did some research on the Internet, we were acknowledged that the architecture should suit dataset class. The original GoogleNet in articles is for large dataset and has too many layers.\n",
        "\n",
        "![Googlenet figure](https://raw.githubusercontent.com/pienight/Machinelearning/master/googlenet%20architecture.png)\n",
        "\n",
        "The modified architecture freezes some layers to have a faster training, retain the convolution layer of GoogleNet, add fully connected layer to have a better accuracy for Flower Dataset. Since the original model of GoogleNet is hard to use, my first thought was to adapt a similar back propagation neural network with original GoogleNet features as a modified work, but it was so hard that time. We used fully connected layer in GoogleNet although it is not originally included.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_pYbuBJ1Jvq",
        "colab_type": "text"
      },
      "source": [
        "# **4.Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ7-YUk21Jxv",
        "colab_type": "text"
      },
      "source": [
        "## **4.1 AlexNet**\n",
        "As shown, when we use the same set of validation data and training model, the first plot is the result of the first run, and the second plot is the result of selecting the best result of graph as a weight.\n",
        "\n",
        "![Alexnet figure1](https://raw.githubusercontent.com/pienight/Machinelearning/master/Alexnet_result.png)\n",
        "\n",
        "When training a model, it often leads to over-fitting of the model. This is most likely caused by two factors. First, there may be situations where the training data is insufficient, which means that the training data cannot estimate the distribution of the entire data. The second is the overtraining model. I think this may be because the data in the flower dataset is insufficient because the training set has 952 images and the test has 272 images. Often, the most common methods to prevent overfitting are: early stop, data expansion, regularization, and dropout.\n",
        "\n",
        "![Alexnet figure2](https://raw.githubusercontent.com/pienight/Machinelearning/master/Alexnet_test.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AodDIdy04zQm",
        "colab_type": "text"
      },
      "source": [
        "## **4.2 VGG16**\n",
        "The structure of VGGNet is very simple. The entire network uses the same size convolution kernel size (3 × 3) and maximum pool size (2 × 2), several small filter (3 × 3) convolution layer combination ratio large filter Concentrator (5 × 5 7 × 7 or) convolutional layer: It has been proven that performance can be improved by continuously deepening the network structure.\n",
        "However, VGG consumes more computing resources and uses more parameters (not 3x3 convolution errors), resulting in more memory usage. \n",
        "\n",
        "These figures below show the model accuracy of the VGG model. The first two graphs are not added with the Dropout layer. It can be seen that the accuracy of the test is about 80%. However, after adding the Dropout layer, the accuracy of the test is significantly improved.\n",
        "\n",
        "![VGG16 figure1](https://raw.githubusercontent.com/pienight/Machinelearning/master/VGG6-result1.png)\n",
        "![VGG16 figure2](https://raw.githubusercontent.com/pienight/Machinelearning/master/VGG6-result2.png)\n",
        "![VGG16 figure3](https://raw.githubusercontent.com/pienight/Machinelearning/master/VGG6-result3.png)\n",
        "![VGG16 figure4](https://raw.githubusercontent.com/pienight/Machinelearning/master/VGG6-result4.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1C5R3Ql45KC",
        "colab_type": "text"
      },
      "source": [
        "## **4.3 GoogleNet**\n",
        "![Googlenet figure1](https://raw.githubusercontent.com/pienight/Machinelearning/master/googlenet%20matrix.png)\n",
        "![Googlenet figure2](https://raw.githubusercontent.com/pienight/Machinelearning/master/Googlenet%20accuracy.png)\n",
        "![Googlenet figure3](https://raw.githubusercontent.com/pienight/Machinelearning/master/googlenet%20result.png)\n",
        "\n",
        "In the process we found that the training fluctuate a lot around epoch 20 and 30 while the model in 25th epoch is the best according to validation. We choose it and conclude the analysis. The cowslip and tulip is a little hard for this model to recognize, especially the cowslip. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utIUAjMXNOQA",
        "colab_type": "text"
      },
      "source": [
        "## **4.4 Summary**\n",
        "Comparing with these three methods, it is obvious that all methods have the ability to predict the data. These three methods are modified upon the baseline of raw models to ensure their feasibility on the flower dataset. All of them are also complemented with dropout to avoid overfitting. However, the best method among them is using Alexnet. The reason that the other two models did not win might be their capability. Googlenet is often used on a large dataset, so in this situation we apply some other methods to adapt it like transfer learning and fully connected layer. The less good method by using VGG16 might have the reason of its advantages. Since the dataset is small and training data is selected randomly, all these three methods have different results each time we run. The results shown above are those acceptable ones. But we believe the VGG16 is badly influenced in a large degree. As for the time cost on training, Alexnet is the fastest. That means Alexnet would also take the advantages for a time-saving consideration in business environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JncMpniB5DCK",
        "colab_type": "text"
      },
      "source": [
        "# **5.Ethical**\n",
        "Is human thinking the same as computer? In today's information age, we can think that computers and human thinking are actually the same, because a large number of algorithms are compiled by humans. However, human beings have the willpower and this willpower is freedom. If human beings are not free, they cannot deny our tendency to act. Kantian called this tendency as “moral law”.\n",
        "In the plant recognition algorithm of us layout, although we really want to gain profit or social recognition of the algorithm, we believe that there is still an obligation to further improve the algorithm. This point is in line with Kantian’s moral law. On the other hand, if we admit that we are responsible for improving the recognition algorithm, we are obligated to be responsible for the accuracy of its predictions and the impact of the algorithm on society. Therefore, we believe that there is still room for improvement in plant identification algorithms, especially in terms of accuracy.\n",
        "In addition, we also believe that the potential misuses of our algorithm will face problems if it is not fully perfected. For example, if this algorithm is applied to other plant identification software, low accuracy may cause problems in plant identification. Some planting users may use the wrong way to grow plants, some users may have a wrong understanding of plants, even some users may consider toxic plants to be non-toxic and eat it. On the other hand, an immature algorithm may lead to the use of illegal companies. Thus causing the problems above to become more widespread. We believe this is a burden that is difficult for us to shirk. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eio5v1DG5JS6",
        "colab_type": "text"
      },
      "source": [
        "# **6.Conclusion**\n",
        "\n",
        "This paper introduces three CNN models, which are used to classify and identify flower datasets. Due to the wide variety of flowers, even experts may have difficulty distinguishing them, so it is necessary to refine the images. At present, there are many softwares for flower identification (Microsoft literacy) that have been formed on the market. Based on this, we can use the deep learning model to classify and identify some items that are not well recognized by humans. Although the accuracy of the three method models is very high, the test accuracy is average, and it is also important for models selected by different data sets. How to optimize the model for different data sets is what we will study and consider next."
      ]
    }
  ]
}